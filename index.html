<meta charset="utf-8">

<meta name="description" content="SPLICE is a part-level neural implicit representation enabling intuitive and structure-aware 3D shape editing, supporting translation, rotation, scaling, deletion, duplication, and cross-shape part mixing with high semantic consistency.">

<meta property="og:title" content="SPLICE: Part-Level 3D Shape Editing"/>
<meta property="og:description" content="SPLICE enables flexible and high-fidelity 3D shape editing through part-level neural implicit representations and global neural mixing."/>
<meta property="og:url" content="URL OF THE WEBSITE"/>
<meta property="og:image" content="static/images/social_preview.png"/>
<meta property="og:image:width" content="1200"/>
<meta property="og:image:height" content="630"/>

<meta name="twitter:title" content="SPLICE: Part-Level 3D Shape Editing">
<meta name="twitter:description" content="A neural implicit framework for flexible part-level 3D shape editing with semantic consistency.">
<meta name="twitter:image" content="static/images/social_preview.png">
<meta name="twitter:card" content="summary_large_image">

<meta name="keywords" content="3D shape editing, neural implicit representation, part-level editing, shape analysis, computer graphics, AI">

<meta name="viewport" content="width=device-width, initial-scale=1">

<title>SPLICE</title>
<link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

<link rel="stylesheet" href="static/css/bulma.min.css">
<link rel="stylesheet" href="static/css/bulma-carousel.min.css">
<link rel="stylesheet" href="static/css/bulma-slider.min.css">
<link rel="stylesheet" href="static/css/fontawesome.all.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link rel="stylesheet" href="static/css/index.css">

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
<script defer src="static/js/fontawesome.all.min.js"></script>
<script src="static/js/bulma-carousel.min.js"></script>
<script src="static/js/bulma-slider.min.js"></script>
<script src="static/js/index.js"></script>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

          <h1 class="title is-1 publication-title">
            SPLICE: Part-Level 3D Shape Editing from Local Semantic Extraction to Global Neural Mixing
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="" target="_blank">Jin Zhou</a>,</span>
            <span class="author-block">
              <a href="" target="_blank">Hongliang Yang</a>,</span>
            <span class="author-block">
              <a href="https://pengfeixu.com/" target="_blank">Pengfei Xu</a>,</span>
            <span class="author-block">
              <a href="https://vcc.tech/~huihuang" target="_blank">Hui Huang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">CSSE, Shenzhen University<br>Pacific Graphics 2025</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- Main PDF link -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2512.04514" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- GitHub link (if you have code, else delete this block) -->
              <!--
              <span class="link-block">
                <a href="https://github.com/YOUR_REPO" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              -->

            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="MRPilot Overview" style="width: 100%; height: auto;"/>
      <h2 class="subtitle has-text-justified" style="margin-top: 20px;">
        <strong>Part-level editing results produced by SPLICE:</strong>  Our method supports a wide range of intuitive editing operations, including sequential edits, copy, move, delete, rotate, scale, and mix, without requiring manual post-adjustment. The edited shapes remain structurally coherent and visually plausible. Additionally, SPLICE exhibits strong robustness under multi-step editing, consistently maintaining high reconstruction quality throughout the editing process.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Neural implicit representations of 3D shapes have shown great potential in 3D shape editing due to their ability to model high-level semantics and continuous geometric representations. However, existing methods often suffer from limited editability, lack of part-level control, and unnatural results when modifying or rearranging shape parts. In this work, we present SPLICE, a novel part-level neural implicit representation of 3D shapes that enables intuitive, structure-aware, and high-fidelity shape editing. By encoding each shape part independently and positioning them using parameterized Gaussian ellipsoids, SPLICE effectively isolates part-specific features while discarding global context that may hinder flexible manipulation. A global attention-based decoder is then employed to integrate parts coherently, further enhanced by an attention-guiding filtering mechanism that prevents information leakage across symmetric or adjacent components. Through this architecture, SPLICE supports various part-level editing operations, including translation, rotation, scaling, deletion, duplication, and cross-shape part mixing. These operations enable users to flexibly explore design variations while preserving semantic consistency and maintaining structural plausibility. Extensive experiments demonstrate that SPLICE outperforms existing approaches both qualitatively and quantitatively across a diverse set of shape-editing tasks. Code will be released upon the acceptance of this paper.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Figure: Overview of SPLICE pipeline -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Overview of SPLICE Pipeline</h2>
    <figure>
      <img src="static/images/pipline.png" alt="Overview of SPLICE pipeline" />
      <figcaption>
        <strong>Figure 1:</strong> Overview of our <strong>SPLICE</strong> pipeline. Given a 3D shape decomposed into parts, we first apply <strong>Part Feature Extraction</strong> using a shared convolutional encoder $f_{\mathrm{enc}}$ to obtain per-part geometry latent codes $\{\mathbf{z}_i\}$ and Gaussian proxies $\{\mathbf{g}_i\}$. In <strong>User Editing and Diffusion-based Refinement</strong>, these proxies can be directly modified by user operations (e.g., move, scale, mix) or adjusted by a latent diffusion model $f_{\mathrm{adj}}$ to restore global coherence. The resulting updated proxies $\{(\mathbf{z}'_i, \mathbf{g}'_i)\}$ are then processed in <strong>Pose Feature Mixing</strong>, where each $\mathbf{g}'_i$ is encoded by a SIREN-based pose encoder $\phi$, and combined with $\mathbf{z}'_i$ via a multilayer perceptron $f_{\mathrm{MLP}}$ to obtain the final part embedding $\mathbf{h}_i$. Finally, in <strong>Attention-based Shape Decoding</strong>, sampled query points attend to $\{\mathbf{h}_i\}$ through a cross-attention transformer $f_{\mathrm{dec}}$, followed by occupancy decoding to reconstruct the final shape via marching cubes.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of copy editing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Copy Editing Results</h2>
    <figure>
      <img src="static/images/op_copy.png" alt="Comparison of copy editing results" />
      <figcaption>
        <strong>Figure 2:</strong> Comparison of the copy editing results between our method and SPAGHETTI.
        <!-- SPAGHETTI implements the copy operation in exactly the same way as our method. However, due to the implicit encoding of part-specific information within its representation, SPAGHETTI often fails to execute the copy operation correctly. In contrast, our method accurately inserts the copied part at the target location. -->
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of delete editing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Delete Editing Results</h2>
    <figure>
      <img src="static/images/op_delete.png" alt="Comparison of delete editing results" />
      <figcaption>
        <strong>Figure 3:</strong> Comparison of delete editing results between our method and SPAGHETTI. The <strong>gray</strong> parts are deleted during the editing.
        <!-- The highlighted parts in <strong>red</strong> will be left. SPAGHETTI's deletion result appears as though the target part is simply erased, often leaving gaps or incomplete sections. In contrast, our method considers the shape's integrity after part removal, ensuring the result remains a cohesive and complete shape. -->
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of move editing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Move Editing Results</h2>
    <figure>
      <img src="static/images/op_move.png" alt="Comparison of move editing results" />
      <figcaption>
        <strong>Figure 4:</strong> Comparison of move editing results between our method and SPAGHETTI and DualSDF. Our method ensures both editing precision and the preservation of shape semantics. For example, in the second row, when the two chair legs are moved closer together, our method accurately completes the move while introducing only minor deformations to maintain a natural and plausible result.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of rotation editing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Rotation Editing Results</h2>
    <figure>
      <img src="static/images/op_rotate.png" alt="Comparison of rotation editing results" />
      <figcaption>
        <strong>Figure 5:</strong> Comparison of rotation editing results between our method and SPAGHETTI. The <strong>purple</strong> parts are rotated during the editing. By incorporating a diffusion model for optimization, our method achieves the desired rotation magnitude without causing unnecessary collateral rotations or distortions to the rest of the shape.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of scaling editing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Scaling Editing Results</h2>
    <figure>
      <img src="static/images/op_scale.png" alt="Comparison of scaling editing results" />
      <figcaption>
        <strong>Figure 6:</strong> Comparison of scaling editing results between our method, SPAGHETTI, and DualSDF. The <strong>yellow</strong> parts are scaled during the editing. Similar to rotation, Our method leverages a diffusion model to adjust the shape encoding, enabling effective and precise axial scaling.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Comparison of part mixing results -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Comparison of Part Mixing Results</h2>
    <figure>
      <img src="static/images/op_mix.png" alt="Comparison of part mixing results" />
      <figcaption>
        <strong>Figure 7:</strong> Comparison of part mixing results between our method and SPAGHETTI.Since our method extracts features for each part independently, mixing parts from different shapes is handled as seamlessly as mixing parts from the same shape. This enables our approach to produce high-quality and coherent results.
      </figcaption>
    </figure>
  </div>
</section>

<!-- Figure: Editing comparisons on the airplane category -->
<section class="section">
  <div class="container">
    <h2 class="title is-3">Editing Comparisons on Airplane Category</h2>
    <figure>
      <img src="static/images/op_airplane-baenet.png" alt="Editing comparisons on the airplane category" />
      <figcaption>
        <strong>Figure 8:</strong> Editing comparisons on the airplane category using our method, DualSDF, and SPAGHETTI. Different colors indicate different types of editing operations.
      </figcaption>
    </figure>
  </div>
</section>


<!-- BibTeX citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX Citation</h2>
    <pre><code>
@inproceedings{Zhou2025SPLICE,
  author    = {Zhou, Jin and Yang, Hongliang and Xu, Pengfei and Huang, Hui},
  title     = {SPLICE: Part‑Level 3D Shape Editing from Local Semantic Extraction to Global Neural Mixing},
  booktitle = {Eurographics / Pacific Graphics 2025 Conference Proceedings},
  year      = {2025},
  publisher = {The Eurographics Association},
  note      = {Full paper, open‑access},
  url       = {https://diglib.eg.org/handle/10.2312/pg20251288},
}
    </code></pre>
  </div>
</section>
<!-- End BibTeX citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

